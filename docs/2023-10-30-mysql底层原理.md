---
title: 'Msql底层原理'
layout: post
tags:
  - mysql
category: 数据库
---
关系型数据库 mysql。

<!--more-->

# 一、运行逻辑
## (a)、从接收的角度
![20231030170238](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231030170238.png)
![20231031102344](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031102344.png)

## (b)、从存储引擎（InnoDB）的角度（提供handlerAPI）
![20231030181732](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231030181732.png)
![20231031103150](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031103150.png)
一切操作都在buffer pool内存中进行，buffer pool根据一定规则去与磁盘进行操作交换数据，操作最小单位为页（16KB，操作系统操作最小单位为4KB，因此需要另一种策略保证页不丢失）

## (c)、存储引擎的区别(4种)
1. MyISAM：如果应用是以查询和插入操作为主，只有极少更新和删除操作，并且对事务的完整性没有要求，没有并发写操作
2. InnoDB：用于事务处理应用程序，支持外键。对事务的完整性有较高要求，除了查询和插入操作外，还有很多更新和删除操作。有效的降低由于删除和更新导致的锁定，还可以确保事务的完整提交和回滚。实现了四个标准的隔离级别，默认级别是可重复读。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ Next-Key Locking 防止幻影读

3. MEMORY：数据存在内存中，默认使用HASH索引，访问速度快，服务关闭数据就会丢失。通常用于更新不太频繁的小表，可以快速得到访问结果。缺陷是对表的大小有限制，表太大无法缓存在内存中，其次要确保表的数据可以恢复
4. MERGE：是一组MyISAM表的组合，这些MyISAM表必须结构完全相同，MERGE表本身没有数据，查询、更新、删除操作实际上是对内部的MyISAM表进行的。DROP操作只是删除MERGE表的定义，对内部的表没有任何影响。优点在于可以突破对单个MyISAM表大小的限制，并且通过将不同的表分布在多个磁盘上，可以有效地改善MERGE表的访问效率

# 二、底层逻辑
## (a)、LOG文件
### Undo Log
![20231031103913](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031103913.png)
![20231031104651](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031104651.png)
![20231031105512](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信图片_20231031105512.png)
#### 解决问题：
1. 原子性：在每个事务中，通过记录每次操作下逻辑相反的语句和链表记录事务版本，从而实现事务的commit和回滚
2. 隔离性（隔离级别：读已提交、可重复读）：其版本链条结合mvcc快照读（read view）机制解决读未提交、不可重复读

#### 逻辑顺序：
1. 在每次事务的操作时，生成一个事务页，便将其链到事务版本管理中
2. 生成一条相反逻辑的语句，写入事务页
3. 事务提交时，先更新bin，在commit标记上redo log，最后将事务标记为已提交
4. 事务回滚时，执行undo log中的语句实现数据回溯，断开该事务的链表前后键

#### 底层结构：
1. 新增：增加insert_rec记录主键即可，通过组件即可完成删除操作以回滚
2. 删除：记录del_mark记录事务id、roll_pointer（数据行的事务版本链）、主键
3. 更新：不更新某一条数据的主键时只需记录upd_exist的事务id、roll_pointer、主键和更新内容；反之，通过一笔新增Insert_rec和一笔删除del_mark两条undo_log操作

### Redo Log（是在InnoDB中的）
![微信截图_20231031111337](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031111337.png)
![微信截图_20231031122756](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031122756.png)
#### 解决问题：
保证mysql操作内存buffer Pool的数据在服务挂掉之后重启能恢复数据（崩溃恢复 / 两阶段提交）

#### 逻辑顺序：
1. 在buffer pool操作之后，立即将操作语句写入redo log buffer（此时未提交）
2. 另启动一个程序根据刷盘策略对redo log buffer的内容进行硬盘存储（默认为每次写入都刷盘）
3. 同时将操作记录在（bin log cache），事务提交后刷盘，并在记录完毕后给redo log打上（已提交）标记服务重启时，先从redo log进行恢复

【注意】也就是说未提交的事务，也有可能被redo log记录，在mysql重启后从redo log读到未提交时将从bin log情况进行判断事务是否完整才会恢复数据

#### redo log刷盘策略：
1. 设置为 0 ：表示每次事务提交时不进行刷盘操作。 （系统默认master thread每隔1秒进行一次重做日志的同步）
2. 设置为 1 ：表示每次事务提交时都将进行同步，刷盘操作 （默认值）
3. 设置为 2 ：表示每次事务提交时都只把 redo log buffer 内容写入 Page Cache ，不进行同步。 由OS自己决定什么时候同步到磁盘文件

### Bin LOG（不在InnoDB等存储引擎中，是mysql独立的日志引擎）
![微信截图_20231031110755](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031110755.png)
![微信截图_20231031111013](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031111013.png)
#### 主要作用
1. 数据恢复：MySQL可以通过bin log恢复某一时刻的误操作的数据，是DBA常打交道的日志
2. 数据复制：MySQL的数据备份、集群高可用、读写分离都是基于bin log的重放实现的

#### 与redo的区别
1. redo log是物理日志，记录内容是“在某个数据页上做了什么修改”，属于InnoDB存储引擎层，在事务过程中是不断写入的。
2. bin log 是逻辑日志，记录内容是语句的原始逻辑，属于Server层，只在事务提交时才写入。

## (b)、idb 物理/逻辑结构
### page - 页（树节点）
![微信截图_20231031130709](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031130709.png)
![微信截图_20231031130835](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031130835.png)
![微信截图_20231031132511](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031132511.png)
![微信截图_20231031143227](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031143227.png)

1. File Header，表示页的一些通用信息，占固定的38字节。
2. Page Header，表示数据页专有的一些信息，占固定的56个字节。
3. Infimum + Supremum，两个虚拟的伪记录，分别表示页中的最小和最大记录，占固定的26个字节。
4. User Records：真实存储我们插入的记录的部分，大小不固定。
5. Free Space：页中尚未使用的部分，大小不确定。
6. Page Directory：页中的某些记录相对位置，也就是各个槽在页面中的地址偏移量，大小不固定，插入的记录越多，这个部分占用的空间越多。
7. File Trailer：用于检验页是否完整的部分，占用固定的8个字节

#### row - 行
![微信截图_20231031130935](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031130935.png)
![微信截图_20231031131114](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031131114.png)

##### 额外信息
1. 可变长列表：记录所有可变长字段类型的长度以便于分配空间
2. NULL列表：使用逆排表示null值，例如null列表使用【0100】倒叙表示真实数据【1列，2列，3列，4列】第三列未null
3. 记录头信息
![微信截图_20231031142809](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031142809.png)
4. 溢出页：当行数据超过16KB（页最大值）时，多余的存储放到溢出页中

##### 行类型(4种)
1. Redundant：是很古老的行格式了， MySQL 5.0 版本之前用的行格式，已弃用
2. Compact：相比于dynamic，会把超过页大小的部分数据前n个字节存到数据行，再把其他放到溢出页
3. Dynamic：从 MySQL5.7 版本之后，默认使用 Dynamic 行格式
4. Compressed：相比dynamic会对数据进行压缩

#### 组、二分查找
在页管理数据行时，对每8个数据行分为一组，并生成目录，查询该页的数据时使用目录和二分查找

### extent - 区（64个连续的页：1MB (64x16K)）
将连续的页放在一块，并在多次重复读取这些页时，直接将整个区读取出来（计算机局部性原理：当使用到某些数据的时候，物理结构下附近的数据也很有可能会被使用到，因此可以把附近的数据也读取出来，以减少重复io）

### segment - 段（256个区：256MB）【逻辑的】
在mysql中page页会构成B+树的叶子，就分为叶子节点和非叶子节点，其中叶子是有真实数据的，非叶子仅存储索引。在mysql中将其分为叶子节点段和非叶子节点段便于管理和搜索

## (c)、idb 数据结构、树、索引
## B+树
![微信截图_20231031145445](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031145445.png)
使用page做树的节点，其中非叶子仅存储主键or索引，叶子才按实际数据行冗余存储，因此page又能分为叶子和非叶子页

### 解决问题
1. 查询成本不确定：将实际数据都存储到叶子节点，非叶子节点仅存储索引（主键、自建索引）+地址，最后查询到数据都必须走到叶子节点（覆盖索引除外：即仅查询索引的内容，无需其他数据行内容），实现查询成本一致计算
2. 树高导致io过多：由于非叶子节点都不存储数据行，因此非叶子节点能存储更多的索引内容，一般一个页能存储300~400个索引时，高度为3个树能存储2000w行数据
3. 范围查询：由于树的有序性，而所有的数据又存储与叶子节点，因此将叶子节点连起来既能形成有序链表，有序链表支持范围查询

### 聚簇索引（一级索引）
定义为当非叶子节点为数据主键，叶子为数据行本身时

### 非聚簇索引（二级索引）
非叶子时自定义索引，叶子为数据行的主键时，通过二级查询数据行时需要走一次二级索引的到主键，再【回表】到一级索引查询数据行（覆盖索引无需走：因为查询索引时已经得到了索引值，不需要再从一级索引的叶子得到数据）

### 索引失效(常见11种)
【注意】当优化器计算消耗时，发现全表比索引快时，会不走索引；优化器会重组sql因此某些写法会被优化成可以走索引的情况；子查询、union、distinct、group by、order by等情况视情况会产生临时表或全表扫描时，则不会走索引

1. 最佳左前缀：使用复合索引时，查询条件必须以复合索引顺序进行查询，必须有左值且不可中断

```sql
#user(username varchar(64),age int(11),add(255))
#假设user表复合索引为idx_username_age_add(username,age,add)

#索引生效
select * from user where username = ?
select * from user where username = ? and age = ?
#like查询字符也是有序的，因此仅匹配左侧是可以生效
select * from user where username = ? and age = ? and add like ?'%'

#索引不生效
select * from user where age = ?
select * from user where add like ?'%'
#仅username生效，没有age因此已经中断了，add没有索引树需要全表
select * from user where username = ? and add like ?'%'

```
2. varchar使用非''查询

```sql
#user(username varchar(64),age varchar(11),add(255))

#索引不生效，因为age被设置为字符，虽然可以使用11查询，但是字符会转化成编码进行排序，而不是数字排序
select * from user where age = 11

```
3. 函数

```sql
#索引不生效
SELECT * FROM `user` WHERE DATE(create_time) = '2020-09-03';
```
4. 运算

```sql
#如果你对列进行了（+，-，*，/，!）, 那么都将不会走索引。
SELECT * FROM `user` WHERE age - 1 = 20;
```
5. or（连接不同字段时）

```sql
#OR导致索引是在特定情况下的，并不是所有的OR都是使索引失效，如果OR连接的是同一个字段，那么索引不会失效，反之索引失效。
SELECT * FROM `user` WHERE `username` = '张三' OR age = '175';
```
6. like（左侧模糊）

```sql
#模糊搜索如果你前缀也进行模糊搜索，那么不会走索引
SELECT * FROM `user` WHERE `username` LIKE '%三';
```
7. != 或 <>

```sql
#需全表扫描
SELECT * FROM `user` WHERE `username` != '冰峰'
```
8. in 或 not in 或 not exist

```sql
#连续则生效，不连续则失效，得看优化器和数据具体情况
SELECT * FROM `user` WHERE `age` in (20,30,40)
SELECT * FROM `user` WHERE `age` in (20,21,22)

#索引失效
SELECT * FROM `user` WHERE `age` not in (20,30,40)
```

9. IS NULL不走索引，IS NOT NULL走索引
根据这个情况，建议大家这设计字段的时候，如果没有必要的要求必须为NULL，那么最好给个默认值空字符串，这可以解决很多后续的麻烦（有深刻的体验<体验=教训>）
```sql
#不走索引。
SELECT * FROM `user` WHERE add IS NULL

#走索引
SELECT * FROM `user` WHERE add IS NOT NULL;
```
10. 两列做比较

```sql
select * from `user` where id > age
```

11. 关联查询，若两个字段【长度、编码】不一致

## (d)、索引优化

### explain解析
![微信截图_20231031160002](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031160002.png)
#### 【type】常见(7种)：性能由好到差依次为：system > const > eq_ref > ref > range > index > all，
1. system：表只有一行记录，这个是const的特例，一般不会出现，可以忽略
2. const：表示通过索引一次就找到了，const用于比较primary key或者unique索引。因为只匹配一行数据，所以很快。
3. eq_ref：唯一性索引扫描，表中只有一条记录与之匹配。一般是两表关联，关联条件中的字段是主键或唯一索引。
4. 【ref】：非唯一行索引扫描，返回匹配某个单独值的所有行（优化程度尽可到ref及以上）
5. range：检索给定范围的行，一般条件查询中出现了>、<、in、between等查询
6. index：遍历索引树。通常比ALL快，因为索引文件通常比数据文件小。all和index都是读全表，但index是从索引中检索的，而all是从硬盘中检索的。
7. all：遍历全表以找到匹配的行

#### 【extra】常见(7种)：
1. Using filesort：使用外部的索引排序，而不是按照表内的索引顺序进行读取。（一般需要优化）
2. Using temporary：使用了临时表保存中间结果。常见于排序order by和分组查询group by（最好优化）
3. Using index：表示select语句中使用了覆盖索引，直接冲索引中取值，而不需要回行（从磁盘中取数据）
4. Using where：使用了where过滤
5. Using index condition：5.6之后新增的，表示查询的列有非索引的列，先判断索引的条件，以减少磁盘的IO
6. Using join buffer：使用了连接缓存
7. impossible where：where子句的值总是false

### 优化策略(3大类)
#### A、sql语句优化(5种)
1. 走复合索引：避免使用select * ，且根据查询所需要的字段建立复合索引，避免回表操作
2. 关联查询：首先尽量避免大表关联、多表复杂关联；关联时也尽量通过where将关联的表缩小

```sql
#user(username、age、add)
#phone(username、phone)
#假设一个用户表和一个电话表，如果年龄age小于18时时没有电话的，则这样
select 
username,phone
from user m
left join phone t1 on m.username = t1.username and m.age >=18
#在关联时就加上age条件范围，以缩小主表m关联次表t1的数据

```
3. 分批处理：在select、update、delete查询或操作大量数据时，都可以考虑分成多个sql进行执行
4. or或!=或<>：使用union代替：变为union时，相当于拆分表并在mysql中聚合

```sql
select * from user from username like ?'%' or age > 10
#替换为
select * from user from username like ?'%'
union
select * from user from username age > 10

```

```sql
select id from orders where amount != 100;
#替换为
(select id from orders where amount > 100) 
union all
(select id from orders where amount < 100 and amount > 0)
```

5. limit缩小范围优化：limit用于分页查询时越往后翻性能越差

```sql
#耗时0.4秒
select * from orders order by id desc limit 0,10

#耗时5.2秒
select * from orders order by id desc limit 1000000,10

#耗时0.5秒：先查询第1000000行id，使用id缩小范围，然后再重新分页
select * from orders 
where id > (select id from orders order by id desc  limit 1000000, 1) 
order by id desc limit 0,10

#耗时0.3秒，如果id绝对连续，可以使用范围查询代替limit
select id from orders where id between 1000000 and 1000010 order by id desc

```

#### B、索引优化（根据实际业务情况并结合索引失效情况来判断）
1. 建立主键，根据业务场景建立复合索引且保证（索引生效）
2. 字段规则不要使用允许null，会导致复合索引失效
3. 在千万级的大表下尽量不要使用范围查询

#### C、表优化（分表分库）
根据表实际数据量情况尽量把表拆分成小而简，避免大而全，然后通过分批处理减少mysql计算压力

1. 垂直拆分：当业务数据是可以用时间，那么可以每月一个表，或者根据自定义某种有序状态来建立多个相同结构的表来减少每个表存储的数据量（减少量）
2. 水平拆分：根据业务状态，比如上线的、下线的、删除的等扭转状态、或是多种状态的大表拆分成好几张表；把变动小的配置表单独存储

# 三、存储引擎
## innodb和myisam的区别
1. InnoDB支持事务，MyISAM不支持，InnoDB【每次】操作都会封装成事务（影响效率）
2. InnoDB支持行锁（当未命中索引和行则退化成表锁），而MyISAM仅支持表级锁
3. InnoDB支持外键，MyISAM不支持，对一个包含外键的InnoDB表转为MYISAM会失败；
4. InnoDB是聚簇索引（所以必须有主键），MyISAM无聚簇之分（无需主键）二级索引也有数据行（无需回表）
5. InnoDB不保存表行数count()全表，MyISAM保存行数（不能有where）

那么为什么InnoDB没有了这个变量呢？

    因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。InnoDB会尝试遍历一个尽可能小的索引除非优化器提示使用别的索引。如果二级索引不存在，InnoDB还会尝试去遍历其他聚簇索引。
    如果索引并没有完全处于InnoDB维护的缓冲区（BufferPool）中，count操作会比较费时。可以建立一个记录总行数的表并让你的程序在INSERT/DELETE时更新对应的数据。和上面提到的问题一样，如果此时存在多个事务的话这种方案也不太好用。如果得到大致的行数值已经足够满足需求可以尝试SHOW TABLE STATUS

6. Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了
7. MyISAM表格可以被压缩后进行查询操作
8. Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI
* Innodb：frm是表定义文件，ibd是数据文件
* Myisam：frm是表定义文件，myd是数据文件，myi是索引文件

## 选择存储引擎的因素
1. 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM
2. 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读也有写，请使用InnoDB。
3. 系统奔溃后，MyISAM恢复起来更困难，能否接受；
4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。

## InnoDB为什么推荐使用自增ID作为主键？
自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差（innoDB使用自增锁保证生成的id自增，但是事务回滚后，自增不会回滚）

## innodb引擎的4大特性
* 插入缓冲（insert buffer)
* 二次写(double write)
* 自适应哈希索引(ahi)
* 预读(read ahead)

# 四、事务机制
## ACID原则
![微信截图_20231031173443](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031173443.png)
* Atomicity原子性：表示每次事务操作不可拆分
* Isolation隔离性：表示多个事务将操作隔离不发生严重冲突
* Durability持久性：事务提交完成后不可变
* Consistency一致性：即数据一致性，当保证了AID即实现C

## 原子性
mysql使用undo log和事务机制实现了一个事务能过够完整的提交或者回滚

## 隔离性
### 读写问题
* 脏读：A事务读到了B事务未提交的数据
![微信截图_20231031173854](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031173854.png)
* 不可重复度：A事务读取后，B事务update提交，A事务再次读取改数据
![微信图片_20231031174028](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信图片_20231031174028.png)
* 幻读：A事务读取范围数据时，B事务对改范围的数据进行了变更操作
![微信截图_20231031174154](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031174154.png)

### 隔离级别
![微信截图_20231031174308](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031174308.png)

### 实现隔离的机制
![微信截图_20231031174954](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031174954.png)
#### 锁
![微信截图_20231031174839](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031174839.png)
![微信截图_20231031174801](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031174801.png)

#### MVCC
基于undo log、版本链、readView(快照)
![微信截图_20231031175215](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031175215.png)
![微信截图_20231031175333](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031175333.png)
* undo log是记录事务的物理存储
* 版本链是管理事务逻辑链表结构，roll_pointer（回滚链）会标记在每一个数据行中，因此每条数据行都有了不同的更新版本
* readView是事务启动时建立的一个事务版本号管理器，记录包括（活跃的、未提交的、已提交的min/max）的事务编号。每次做读取操作可以通过比对数据行中的roll_pointer确定该readView下应该读取到哪一版本的数据，从而实现了读取快照内容

1. 实现读已提交：每次读取生成readView快照读从而避免读到未提交的事务，每次写入都加行锁禁止读写
2. 实现可重复读（默认）：一个事务仅在开头生成一份readView保证整个事务读取时都是用一个版本，锁住读取到数据防止其他事务读写（如果是范围数据且结合next-key锁可以防止部分幻读），写时使用锁防止读写
3. 串行化：对【读写】操作都加【表锁】

## 持久性
基于bin LOG（和InnoDB的redo LOG）的日志机制
![微信截图_20231031181644](https://raw.githubusercontent.com/QinL233/QinL233.github.io/master/images/微信截图_20231031181644.png)

# 五、高可用
* 主从复制
1. 主库将数据库的变更操作记录到Binlog日志文件中
2. 从库读取主库中的Binlog日志文件信息写入到从库的Relay Log中继日志中
3. 从库读取中继日志信息在从库中进行Replay,更新从库数据信息
* 读写分离